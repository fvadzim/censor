{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be looking at how to apply deep learning techniques to the task of sentiment analysis. Sentiment analysis can be thought of as the exercise of taking a sentence, paragraph, document, or any piece of natural language, and determining whether that text's emotional tone is positive, negative or neutral. \n",
    "\n",
    "This notebook will go through numerous topics like word vectors, recurrent neural networks, and long short-term memory units (LSTMs). After getting a good understanding of these terms, we’ll walk through concrete code examples and a full Tensorflow sentiment classifier at the end.\n",
    "\n",
    "Before getting into the specifics, let's discuss the reasons why deep learning fits into natural language processing (NLP) tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language processing is all about creating systems that process or “understand” language in order to perform certain tasks. These tasks could include:\n",
    "\n",
    "* Question Answering - The main job of technologies like Siri, Alexa, and Cortana\n",
    "* Sentiment Analysis - Determining the emotional tone behind a piece of text\n",
    "* Image to Text Mappings - Generating a caption for an input image\n",
    "* Machine Translation - Translating a paragraph of text to another language\n",
    "* Speech Recognition - Having computers recognize spoken words\n",
    "\n",
    "In the pre-deep learning era, NLP was a thriving field that saw lots of different advancements. However, in all of the successes in the aforementioned tasks, one needed to do a lot of feature enginering and thus had to have a lot of domain knowledge in linguistics. Entire 4 year degrees are devoted to this field of study, as practitioners needed to be comfortable with terms like phonemes and morphemes. In the past few years, deep learning has seen incredible progress and has largely removed the requirement of strong domain knowledge. As a result of the lower barrier to entry, applications to NLP tasks have been one of the biggest areas of deep learning research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand how deep learning can be applied, think about all the different forms of data that are used as inputs into machine learning or deep learning models. Convolutional neural networks use arrays of pixel values, logistic regression uses quantifiable features, and reinforcement learning models use reward signals. The common theme is that the inputs need to be scalar values, or matrices of scalar values. When you think of NLP tasks, however, a data pipeline like this may come to mind. \n",
    " \n",
    "![caption](Images/SentimentAnalysis.png)\n",
    "\n",
    "This kind of pipeline is problematic. There is no way for us to do common operations like dot products or backpropagation on a single string. Instead of having a string input, we will need to convert each word in the sentence to a vector. \n",
    "\n",
    "![caption](Images/SentimentAnalysis2.png)\n",
    "\n",
    "You can think of the input to the sentiment analysis module as being a 16 x D dimensional matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want these vectors to be created in such a way that they somehow represent the word and its context, meaning, and semantics. For example, we’d like the vectors for the words “love” and “adore” to reside in relatively the same area in the vector space since they both have similar definitions and are both used in similar contexts. The vector representation of a word is also known as a word embedding.\n",
    "\n",
    "![caption](Images/SentimentAnalysis8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create these word embeddings, we'll use a model that's commonly reffered to as \"Word2Vec\". Without going into too much detail, the model creates word vectors by looking at the context with which words appear in sentences. Words with similar contexts will be placed close together in the vector space. In natural language, the context of words can be very important when trying to determine their meanings. Taking our previous example of the words \"adore\" and \"love\", consider the types of sentences we'd find these words in.\n",
    "\n",
    "![caption](Images/SentimentAnalysis9.png)\n",
    "\n",
    "From the context of the sentences, we can see that both words are generally used in sentences with positive connotations and generally precede nouns or noun phrases. This is an indication that both words have something in common and can possibly be synonyms. Context is also very important when considering grammatical structure in sentences. Most sentences will follow traditional paradigms of having verbs follow nouns, adjectives precede nouns, and so on. For this reason, the model is more likely to position nouns in the same general area as other nouns. The model takes in a large dataset of sentences (English Wikipedia for example) and outputs vectors for each unique word in the corpus. The output of a Word2Vec model is called an embedding matrix.\n",
    "\n",
    "![caption](Images/SentimentAnalysis3.png)\n",
    "\n",
    "This embedding matrix will contain vectors for every distinct word in the training corpus. Traditionally, embedding matrices can contain over 3 million word vectors.\n",
    "\n",
    "The Word2Vec model is trained by taking each sentence in the dataset, sliding a window of fixed size over it, and trying to predict the center word of the window, given the other words. Using a loss function and optimization procedure, the model generates vectors for each unique word. The specifics of this training procedure can get a little complicated, so we’re going to skip over the details for now, but the main takeaway here is that inputs into any Deep Learning approach to an NLP task will likely have word vectors as input.\n",
    "\n",
    "For more information on the theory behind Word2Vec and how you create your own embeddings, check out Tensorflow's [tutorial](https://www.tensorflow.org/tutorials/word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our word vectors as input, let's look at the actual network architecture we're going to be building. The unique aspect of NLP data is that there is a temporal aspect to it. Each word in a sentence depends greatly on what came before and comes after it. In order to account for this dependency, we use a recurrent neural network.  \n",
    "\n",
    "The recurrent neural network structure is a little different from the traditional feedforward NN you may be accostumed to seeing. The feedforward network consists of input nodes, hidden units, and output nodes. \n",
    "\n",
    "![caption](Images/SentimentAnalysis17.png)\n",
    "\n",
    "The main difference between feedforward neural networks and recurrent ones is the temporal aspect of the latter. In RNNs, each word in an input sequence will be associated with a specific time step. In effect, the number of time steps will be equal to the max sequence length. \n",
    "\n",
    "![caption](Images/SentimentAnalysis18.png)\n",
    "\n",
    "Associated with each time step is also a new component called a hidden state vector h<sub>t</sub>. From a high level, this vector seeks to encapsulate and summarize all of the information that was seen in the previous time steps. Just like x<sub>t</sub> is a vector that encapsulates all the information of a specific word, h<sub>t</sub> is a vector that summarizes information from previous time steps.\n",
    "\n",
    "The hidden state is a function of both the current word vector and the hidden state vector at the previous time step. The sigma indicates that the sum of the two terms will be put through an activation function (normally a sigmoid or tanh).\n",
    "\n",
    "![caption](Images/SentimentAnalysis15.png)\n",
    "\n",
    "The 2 W terms in the above formulation represent weight matrices. If you take a close look at the superscripts, you’ll see that there’s a weight matrix W<sup>X</sup> which we’re going to multiply with our input, and there’s a recurrent weight matrix W<sup>H</sup> which is multiplied with the hidden state vector at the previous time step. W<sup>H</sup> is a matrix that stays the same across all time steps, and the weight matrix W<sup>X</sup> is different for each input. \n",
    "\n",
    "The magnitude of these weight matrices impact the amount the hidden state vector is affected by either the current vector or the previous hidden state. As an exercise, take a look at the above formula, and consider how h<sub>t</sub> would change if either W<sup>X</sup> or W<sup>H</sup> had large or small values. \n",
    "\n",
    "Let's look at a quick example. When the magnitude of W<sup>H</sup> is large and the magnitude of W<sup>X</sup> is small, we know that h<sub>t</sub> is largely affected by h<sub>t-1</sub> and unaffected by x<sub>t</sub>. In other words, the current hidden state vector sees that the current word is largely inconsequential to the overall summary of the sentence, and thus it will take on mostly the same value as the vector at the previous time step. \n",
    "\n",
    "The weight matrices are updated through an optimization process called backpropagation through time. \n",
    "\n",
    "The hidden state vector at the final time step is fed into a binary softmax classifier where it is multiplied by another weight matrix and put through a softmax function that outputs values between 0 and 1, effectively giving us the probabilities of positive and negative sentiment. \n",
    "\n",
    "![caption](Images/SentimentAnalysis16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory Units (LSTMs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Memory Units are modules that you can place inside of reucrrent neural entworks. At a high level, they make sure that the hidden state vector h is able to encapsulate information about long term dependencies in the text. As we saw in the previous section, the formulation for h in traditional RNNs is relatively simple. This approach won't be able to effectively connect together information that is separated by more than a couple time steps. We can illiustrate this idea of handling long term dependencies through an example in the field of question answering. The function of question answering models is to take an a passage of text, and answer a question about its content. Let's look at the following example.\n",
    "\n",
    "![caption](Images/SentimentAnalysis4.png)\n",
    "\n",
    "Here, we see that the middle sentence had no impact on the question that was asked. However, there is a strong connection between the first and third sentences. With a classic RNN, the hidden state vector at the end of the network might have stored more information about the dog sentence than about the first sentence about the number. Basically, the addition of LSTM units make it possible to determine the correct and useful information that needs to be stored in the hidden state vector.\n",
    "\n",
    "Looking at LSTM units from a more technical viewpoint, the units take in the current word vector x<sub>t</sub> and output the hidden state vector h<sub>t</sub>. In these units, the formulation for h<sub>t</sub> will be a bit more complex than that in a typical RNN. The computation is broken up into 4 components, an input gate, a forget gate, an output gate, and a new memory container. \n",
    "\n",
    "![caption](Images/SentimentAnalysis10.png)\n",
    "\n",
    "Each gate will take in x<sub>t</sub> and h<sub>t-1</sub> (not shown in image) as inputs and will perform some computation on them to obtain intermediate states. Each intermediate state gets fed into different pipelines and eventually the information is aggregated to form h<sub>t</sub>. For simplicity sake, we won't go into the specific formulations for each gate, but it's worth noting that each of these gates can be thought of as different modules within the LSTM that each have different functions. The input gate determines how much emphasis to put on each of the inputs, the forget gate determines the information that we'll throw away, and the output gate determines the final h<sub>t</sub> based on the intermediate states. For more information on understanding the functions of the different gates and the full equations, check out Christopher Olah's great [blog post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
    "\n",
    "Looking back at the first example with question “What is the sum of the two numbers?”, the model would have to be trained on similar types of questions and answers. The LSTM units would then be able to realize that any sentence without numbers will likely not have an impact on the answer to the question, and thus the unit will be able to utilize its forget gate to discard the unnecessary information about the dog, and rather keep the information regarding the numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framing Sentiment Analysis as a Deep Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, the task of sentiment analysis involves taking in an input sequence of words and determining whether the sentiment is positive, negative, or neutral. We can separate this specific task (and most other NLP tasks) into 5 different components.\n",
    "\n",
    "    1) Training a word vector generation model (such as Word2Vec) or loading pretrained word vectors\n",
    "    2) Creating an ID's matrix for our training set (We'll discuss this a bit later)\n",
    "    3) RNN (With LSTM units) graph creation\n",
    "    4) Training \n",
    "    5) Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to create our word vectors. For simplicity, we're going to be using a pretrained model. \n",
    "\n",
    "As one of the biggest players in the ML game, Google was able to train a Word2Vec model on a massive Google News dataset that contained over 100 billion different words! From that model, Google [was able to create 3 million word vectors](https://code.google.com/archive/p/word2vec/#Pre-trained_word_and_phrase_vectors), each with a dimensionality of 300. \n",
    "\n",
    "In an ideal scenario, we'd use those vectors, but since the word vectors matrix is quite large (3.6 GB!), we'll be using a much more manageable matrix that is trained using [GloVe](http://nlp.stanford.edu/projects/glove/), a similar word vector generation model. The matrix will contain 400,000 word vectors, each with a dimensionality of 50. \n",
    "\n",
    "We're going to be importing two different data structures, one will be a Python list with the 400,000 words, and one will be a 400,000 x 50 dimensional embedding matrix that holds all of the word vector values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure everything has been loaded in correctly, we can look at the dimensions of the vocabulary list and the embedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search our word list for a word like \"baseball\", and then access its corresponding vector through the embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9327  ,  1.0421  , -0.78515 ,  0.91033 ,  0.22711 , -0.62158 ,\n",
       "       -1.6493  ,  0.07686 , -0.5868  ,  0.058831,  0.35628 ,  0.68916 ,\n",
       "       -0.50598 ,  0.70473 ,  1.2664  , -0.40031 , -0.020687,  0.80863 ,\n",
       "       -0.90566 , -0.074054, -0.87675 , -0.6291  , -0.12685 ,  0.11524 ,\n",
       "       -0.55685 , -1.6826  , -0.26291 ,  0.22632 ,  0.713   , -1.0828  ,\n",
       "        2.1231  ,  0.49869 ,  0.066711, -0.48226 , -0.17897 ,  0.47699 ,\n",
       "        0.16384 ,  0.16537 , -0.11506 , -0.15962 , -0.94926 , -0.42833 ,\n",
       "       -0.59457 ,  1.3566  , -0.27506 ,  0.19918 , -0.36008 ,  0.55667 ,\n",
       "       -0.70315 ,  0.17157 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseballIndex = wordsList.index('baseball')\n",
    "wordVectors[baseballIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our vectors, our first step is taking an input sentence and then constructing the its vector representation. Let's say that we have the input sentence \"I thought the movie was incredible and inspiring\". In order to get the word vectors, we can use Tensorflow's embedding lookup function. This function takes in two arguments, one for the embedding matrix (the wordVectors matrix in our case), and one for the ids of each of the words. The ids vector can be thought of as the integerized representation of the training set. This is basically just the row index of each of the words. Let's look at a quick example to make this concrete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "#firstSentence[8] and firstSentence[9] are going to be 0\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data pipeline can be illustrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 x 50 output should contain the 50 dimensional word vectors for each of the 10 words in the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the ids matrix for the whole training set, let’s first take some time to visualize the type of data that we have. This will help us determine the best value for setting our maximum sequence length. In the previous example, we used a max length of 10, but this value is largely dependent on the inputs you have.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set we're going to use is the Imdb movie review dataset. This set has 25,000 movie reviews, with 12,500 positive reviews and 12,500 negative reviews. Each of the reviews is stored in a txt file that we need to parse through. The positive reviews are stored in one directory and the negative reviews are stored in another. The following piece of code will determine total and average number of words in each review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive files finished\n",
      "Negative files finished\n",
      "The total number of files is 25000\n",
      "The total number of words in the files is 5844680\n",
      "The average number of words in the files is 233.7872\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "positiveFiles = ['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
    "negativeFiles = ['negativeReviews/' + f for f in listdir('negativeReviews/') if isfile(join('negativeReviews/', f))]\n",
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)       \n",
    "print('Positive files finished')\n",
    "\n",
    "for nf in negativeFiles:\n",
    "    with open(nf, \"r\", encoding='utf-8') as f:\n",
    "        line=f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)  \n",
    "print('Negative files finished')\n",
    "\n",
    "numFiles = len(numWords)\n",
    "print('The total number of files is', numFiles)\n",
    "print('The total number of words in the files is', sum(numWords))\n",
    "print('The average number of words in the files is', sum(numWords)/len(numWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the Matplot library to visualize this data in a histogram format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nObmYmVnlnFzMzKxyTi5mZla5/w+bvdrW6fGbcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde8fb81eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram as well as the average number of words per file, we can safely say that most reviews will fall under 250 words, which is the max sequence length value we will set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can take a single file and transform it into our ids matrix. This is what one of the reviews looks like in text file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Director Vincenzo Natali first showed his penchant for character-based sci-fi flicks with his 1997 short film \"Elevated\", wherein 3 people remain trapped in an elevator while unseen monsters roam the building. His follow-up feature project \"Cube\", released later that year, had a very similar premise, this time with 6 people and instead of an elevator it was a vast expansion of interlocking cubic deathtraps. Both were admirable attempts to take the sci-fi genre a step further, by deliberately declining to show almost any visual stimulation, choosing instead to spend as much time as possible focusing on the human element, how the characters act, react and interact under incomprehensible and dangerous conditions. After his exploration into the mainstream with 2002's \"Cypher\", Natali has come back to his bizarre character-film trend to bring us \"Nothing\", his latest, and by far most optimistic and comedic take on the wide cinematic world of \"What If?\"<br /><br />Dave (David Hewlett) and Andrew (Andrew Miller) are life-long friends, brought together by a mutual detachment from society and a lack of any one else to be with. Dave, who has always been hindered by a selfish and somewhat dimwitted nature, lives rent-free with Andrew at his ill-located and ill-constructed house, where he often takes advantage of Andrew's neurotic and antisocial mentality. Despite all this, the two misfits are happy together, until one day their deep character flaws, coupled with some astronomically bad luck, land them in the middle of some pretty serious, jail-sentence-worthy trouble. On top of this, they discover that their house has been deemed unfit for existence and is scheduled to be demolished before sunset, so in the hazy, nightmarish panic of everything going wrong for them, they wish that the whole world would just disappear. And it does.<br /><br />Going any further with the synopsis would compromise a lot of the film's slow (occasionally too slow) reveal about what's happened to Dave and Andrew, and how they deal with their new reality. Natali's fascination with studying human behavior under duress (ala The Birds) is here in spades, but simply by making the main characters friends rather than strangers, he's able to break away from the thriller-horror element of this premise to open it up to a more comfortable and optimistic level. It's almost as if he's made the aphoristic opposite of \"Cube\".<br /><br />Of course, the film is not 85 minutes of laughter and sunshine. In keeping with fundamental realism, our two anti-heroes' dynamic often becomes antagonistic, sometimes with rather nasty results. Like the \"Desert Island\" game, the film looks at how even best friends, when left alone together, can fall apart, but at the same time it shows that friends are vital to the quality of existence. In a very twisted, sci-fi way, this is a feel-good flick, with good heart and good intentions.<br /><br />However, there are a few qualms to be had with \"Nothing\". While the two lead actors, Hewlett and Miller, do well with their parts, their characters are not nearly as interesting as they should have been, considering it is completely up to them to entertain us for the better part of an hour. There is some development in the relationship and personalities of Dave and Andrew, some background is given, but ultimately not enough. A generous viewer will sit through the less-engaging portions of the film to see it through to the end, but cynics will probably give up pretty fast.<br /><br />Acting, as mentioned, is adequate, and considering the amount of 'green-screen' work that would've been needed, reasonably convincing. David Hewlett and Andrew Miller, who both wrote co-wrote the screenplay, have been long-time friends of Vincenzo Natali: Hewlett has in fact featured in every film Natali has made. Perhaps it was their creative input that steered this film in a more positive direction. Nonetheless, the story could have been a lot more involving. Granted, it is relatively entertaining considering that (no pun intended) nothing really happens, but you get the impression that, in more experienced hands, a lot more could've been done with this premise.<br /><br />In all fairness, \"Nothing\" is an impressive piece of work in many ways. The concept is interesting, the direction is inventive, the script works on a human level and, most of all, it shows a progression in Natali's creative mentality. For fans of his work, this will be a delight, and for others it will be a nice way to pass a little unwanted time. It's just a shame that the director's fixation on human drama prevented it from being the great, fun film it could have been.\n"
     ]
    }
   ],
   "source": [
    "fname = positiveFiles[3] #Can use any valid index (not just 3)\n",
    "with open(fname) as f:\n",
    "    for lines in f:\n",
    "        print(lines)\n",
    "        exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's convert to to an ids matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   369,  23604, 120572,     58,    896,     26,  19732,     10,\n",
       "       399999, 130772,  33619,     17,     26,    996,    636,    319,\n",
       "         7793,  21640,    314,     69,    944,   4799,      6,     29,\n",
       "        12202,    110,  18871,  12956,  20810, 201534,    447,     26,\n",
       "        55074,   2047,    716,  15936,    356,    168,     12,     62,\n",
       "           40,      7,    191,    793,  11932,     37,     79,     17,\n",
       "          524,     69,      5,    773,      3,     29,  12202,     20,\n",
       "           15,      7,   3083,   2346,      3,  35350,   6573, 320501,\n",
       "          150,     35,  23277,   2444,      4,    190, 201534, 130772,\n",
       "         6616,      7,   1065,    489,     21,   7689,   5232,      4,\n",
       "          273,    591,    130,   5097,  22195,   7145,    773,      4,\n",
       "         2025,     19,    181,     79,     19,    555,   5038,     13,\n",
       "       201534,    473,   4736,    197, 201534,   2153,    743,   8201,\n",
       "            5,  12574,    124,  29466,      5,   2292,   1124,     49,\n",
       "           26,   5679,     75, 201534,   4826,     17, 399999,  61856,\n",
       "       120572,     31,    326,    137,      4,     26,   9520, 399999,\n",
       "         3287,      4,    938,     95,    936,     26,    993,      5,\n",
       "           21,    372,     96,   4632,      5,  21698,    190,     13,\n",
       "       201534,   1260,  17603,     85,      3,    102,     83,   4010,\n",
       "          684,  11330,      5,   2631,   2631,   2452,     32,  10675,\n",
       "         1095,    845,    600,     21,      7,   3046,  14497,     25,\n",
       "          908,      5,      7,   1492,      3,    130,     48,   1726,\n",
       "            4,     30,     17,   4010,     38,     31,    690,     51,\n",
       "        18477,     21,      7,  19216,      5,   3779,  81189,   1746,\n",
       "          973, 399999,     17,   2631,     22,     26, 399999,      5,\n",
       "       399999,    166,    111,     18,    456,   1144,   1979,      3,\n",
       "         7949,  35384,      5,  52170,  13436,    504,     64,     37,\n",
       "       201534,     55,  40547,     32,   1751,    600,    207,     48,\n",
       "          122,     44,   1479,   1395,  12087,   8923,     17,     77,\n",
       "       105875,    978,   5556,    607,    101,      6, 201534,    699,\n",
       "            3,     77,   1922,   1034, 399999,   2194,     13,    220,\n",
       "            3,     37], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
    "with open(fname) as f:\n",
    "    indexCounter = 0\n",
    "    line=f.readline()\n",
    "    cleanedLine = cleanSentences(line)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        if indexCounter < maxSeqLength:\n",
    "            try:\n",
    "                firstFile[indexCounter] = wordsList.index(word)\n",
    "            except ValueError:\n",
    "                firstFile[indexCounter] = 399999 #Vector for unknown words\n",
    "        indexCounter = indexCounter + 1\n",
    "firstFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same for each of our 25,000 reviews. We'll load in the movie training set and integerize it to get a 25000 x 250 matrix. This was a computationally expensive process, so instead of having you run the whole piece, we’re going to load in a pre-computed IDs matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "# fileCounter = 0\n",
    "# for pf in positiveFiles:\n",
    "#    with open(pf, \"r\") as f:\n",
    "#        indexCounter = 0\n",
    "#        line=f.readline()\n",
    "#        cleanedLine = cleanSentences(line)\n",
    "#        split = cleanedLine.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#            except ValueError:\n",
    "#                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#            indexCounter = indexCounter + 1\n",
    "#            if indexCounter >= maxSeqLength:\n",
    "#                break\n",
    "#        fileCounter = fileCounter + 1 \n",
    "\n",
    "# for nf in negativeFiles:\n",
    "#    with open(nf, \"r\") as f:\n",
    "#        indexCounter = 0\n",
    "#        line=f.readline()\n",
    "#        cleanedLine = cleanSentences(line)\n",
    "#        split = cleanedLine.split()\n",
    "#        for word in split:\n",
    "#            try:\n",
    "#                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#            except ValueError:\n",
    "#                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#            indexCounter = indexCounter + 1\n",
    "#            if indexCounter >= maxSeqLength:\n",
    "#                break\n",
    "#        fileCounter = fileCounter + 1 \n",
    "# #Pass into embedding function and see if it evaluates. \n",
    "\n",
    "# np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.load('idsMatrix.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can find a couple of helper functions that will be useful when training the network in a later step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0): \n",
    "            num = randint(1,11499)\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            num = randint(13499,24999)\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(11499,13499)\n",
    "        if (num <= 12499):\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we’re ready to start creating our Tensorflow graph. We’ll first need to define some hyperparameters, such as batch size, number of LSTM units, number of output classes, and number of training iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with most Tensorflow graphs, we’ll now need to specify two placeholders, one for the inputs into the network, and one for the labels. The most important part about defining these placeholders is understanding each of their dimensionalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels placeholder represents a set of values, each either [1, 0] or [0, 1], depending on whether each training example is positive or negative. Each row in the integerized input placeholder represents the integerized representation of each training example that we include in our batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our input data placeholder, we’re going to call the tf.nn.lookup() function in order to get our word vectors. The call to that function will return a 3-D Tensor of dimensionality batch size by max sequence length by word vector dimensions. In order to visualize this 3-D tensor, you can simply think of each data point in the integerized input tensor as the corresponding D dimensional vector that it refers to. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data in the format that we want, let’s look at how we can feed this input into an LSTM network. We’re going to call the tf.nn.rnn_cell.BasicLSTMCell function. This function takes in an integer for the number of LSTM units that we want. This is one of the hyperparameters that will take some tuning to figure out the optimal value. We’ll then wrap that LSTM cell in a dropout layer to help prevent the network from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we’ll feed both the LSTM cell and the 3-D tensor full of input data into a function called tf.nn.dynamic_rnn. This function is in charge of unrolling the whole network and creating a pathway for the data to flow through the RNN graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, another more advanced network architecture choice is to stack multiple LSTM cells on top of each other. This is where the final hidden state vector of the first LSTM feeds into the second. Stacking these cells is a great way to help the model retain more long term dependence information, but also introduces more parameters into the model, thus possibly increasing the training time, the need for additional training examples, and the chance of overfitting. For more information on how you can add stacked LSTMs to your model, check out Tensorflow's excellent [documentation](https://www.tensorflow.org/tutorials/recurrent#stacking_multiple_lstms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first output of the dynamic RNN function can be thought of as the last hidden state vector. This vector will be reshaped and then multiplied by a final weight matrix and a bias term to obtain the final output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll define correct prediction and accuracy metrics to track how the network is doing. The correct prediction formulation works by looking at the index of the maximum value of the 2 output values, and then seeing whether it matches with the training labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll define a standard cross entropy loss with a softmax layer put on top of the final prediction values. For the optimizer, we’ll use Adam and the default learning rate of .001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’d like to use Tensorboard to visualize the loss and accuracy values, you can also run and the modify the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the right values for your hyperparameters is a crucial part of training deep neural networks effectively. You'll find that your training loss curves can vary with your choice of optimizer (Adam, Adadelta, SGD, etc), learning rate, and network architecture. With RNNs and LSTMs in particular, some other important factors include the number of LSTM units and the size of the word vectors.\n",
    "\n",
    "* Learning Rate: RNNs are infamous for being diffult to train because of the large number of time steps they have. Learning rate becomes extremely important since we don't want our weight values to fluctuate wildly as a result of a large learning rate, nor do we want a slow training process due to a low learning rate. The default value of 0.001 is a good place to start. You should increase this value if the training loss is changing very slowly, and decrease if the loss is unstable.  \n",
    "* Optimizer: There isn't a consensus choice among researchers, but Adam has been widely popular due to having the adaptive learning rate property (Keep in mind that optimal learning rates can differ with the choice of optimizer).\n",
    "* Number of LSTM units: This value is largely dependent on the average length of your input texts. While a greater number of units provides more expressibility for the model and allows the model to store more information for longer texts, the network will take longer to train and will be computationally expensive. \n",
    "* Word Vector Size: Dimensions for word vectors generally range from 50 to 300. A larger size means that the vector is able to encapsulate more information about the word, but you should also expect a more computationally expensive model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of the training loop is that we first define a Tensorflow session. Then, we load in a batch of reviews and their associated labels. Next, we call the session’s `run` function. This function has two arguments. The first is called the \"fetches\" argument. It defines the value we’re interested in computing. We want our optimizer to be computed since that is the component that minimizes our loss function. The second argument is where we input our `feed_dict`. This data structure is where we provide inputs to all of our placeholders. We need to feed our batch of reviews and our batch of labels. This loop is then repeated for a set number of training iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training the network in this notebook (which will take at least a couple of hours), we’ll load in a pretrained model.\n",
    "\n",
    "If you decide to train this notebook on your own machine, note that you can track its progress using [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard). While the following cell is running, use your terminal to enter the directory that contains this notebook, enter `tensorboard --logdir=tensorboard`, and visit http://localhost:6006/ with a browser to keep an eye on your training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for i in range(iterations):\n",
    "#    #Next Batch of reviews\n",
    "#    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "#    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "#    #Write summary to Tensorboard\n",
    "#    if (i % 50 == 0):\n",
    "#        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "#        writer.add_summary(summary, i)\n",
    "\n",
    "#    #Save the network every 10,000 training iterations\n",
    "#    if (i % 10000 == 0 and i != 0):\n",
    "#        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "#        print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pretrained model’s accuracy and loss curves during training can be found below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](Images/SentimentAnalysis6.png)\n",
    "![caption](Images/SentimentAnalysis7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the training curves above, it seems that the model's training is going well. The loss is decreasing steadily, and the accuracy is approaching 100 percent. However, when analyzing training curves, we should also pay special attention to the possibility of our model overfitting the training dataset. Overfitting is a common phenomenon in machine learning where a model becomes so fit to the training data that it loses the ability to generalize to the test set. This means that training a network until you achieve 0 training loss might not be the best way to get an accurate model that performs well on data it has never seen before. Early stopping is an intuitive technique commonly used with LSTM networks to combat this issue. The basic idea is that we train the model on our training set, while also measuring its performance on the test set every now and again. Once the test error stops its steady decrease and begins to increase instead, you'll know to stop training, since this is a sign that the network has begun to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a pretrained model involves defining another Tensorflow session, creating a Saver object, and then using that object to call the restore function. This function takes into 2 arguments, one for the current session, and one for the name of the saved model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x7fde8c566f28>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.pywrap_tensorflow_internal.CheckpointReader; proxy of <Swig Object of type 'tensorflow::checkpoint::CheckpointReader *' at 0x7fde8c4670f0> >\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'save_2/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: save_2/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save_2/Const, save_2/SaveV2/tensor_names, save_2/SaveV2/shape_and_slices, Variable, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, beta1_power, beta2_power, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n\nCaused by op 'save_2/SaveV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-92db0fe0cf4e>\", line 3, in <module>\n    saver = tf.train.Saver()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save_2/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: save_2/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save_2/Const, save_2/SaveV2/tensor_names, save_2/SaveV2/shape_and_slices, Variable, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, beta1_power, beta2_power, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1354\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'save_2/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: save_2/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save_2/Const, save_2/SaveV2/tensor_names, save_2/SaveV2/shape_and_slices, Variable, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, beta1_power, beta2_power, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5e28717bc9c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEW_CHECKPOINT_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'save_2/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: save_2/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save_2/Const, save_2/SaveV2/tensor_names, save_2/SaveV2/shape_and_slices, Variable, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, beta1_power, beta2_power, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n\nCaused by op 'save_2/SaveV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-92db0fe0cf4e>\", line 3, in <module>\n    saver = tf.train.Saver()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save_2/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n\t [[Node: save_2/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/device:GPU:0\"](save_2/Const, save_2/SaveV2/tensor_names, save_2/SaveV2/shape_and_slices, Variable, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, beta1_power, beta2_power, rnn/basic_lstm_cell/bias, rnn/basic_lstm_cell/bias/Adam, rnn/basic_lstm_cell/bias/Adam_1, rnn/basic_lstm_cell/kernel, rnn/basic_lstm_cell/kernel/Adam, rnn/basic_lstm_cell/kernel/Adam_1)]]\n"
     ]
    }
   ],
   "source": [
    "models_path = \"models/checkpoint\"\n",
    "OLD_CHECKPOINT_FILE = \"models/pretrained_lstm.ckpt-90000.data-00000-of-00001\"\n",
    "NEW_CHECKPOINT_FILE = \"models/pretrained_lstm2.ckpt-90000.data-00000-of-00001\"\n",
    "\n",
    "vars_to_rename = {\n",
    "    \"lstm/basic_lstm_cell/weights\": \"lstm/basic_lstm_cell/kernel\",\n",
    "    \"lstm/basic_lstm_cell/biases\": \"lstm/basic_lstm_cell/bias\",\n",
    "}\n",
    "new_checkpoint_vars = {}\n",
    "reader = tf.train.latest_checkpoint(\"models\")\n",
    "reader = tf.train.NewCheckpointReader(reader)\n",
    "print(reader)\n",
    "for old_name in reader.get_variable_to_shape_map():\n",
    "  if old_name in vars_to_rename:\n",
    "    new_name = vars_to_rename[old_name]\n",
    "  else:\n",
    "    new_name = old_name\n",
    "  new_checkpoint_vars[new_name] = tf.Variable(reader.get_tensor(old_name))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(new_checkpoint_vars)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  saver.save(sess, NEW_CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.4.0-19-ga52c8d9 1.4.1\n",
      "сpu\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown attribute: 'сpu' in '/сpu:0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-7994d027d5dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'сpu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/{}:0'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'var{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvari\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self, device_name_or_function)\u001b[0m\n\u001b[1;32m   3731\u001b[0m     if (device_name_or_function is not None and\n\u001b[1;32m   3732\u001b[0m         not callable(device_name_or_function)):\n\u001b[0;32m-> 3733\u001b[0;31m       \u001b[0mdevice_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name_or_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3734\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3735\u001b[0m       \u001b[0mdevice_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_name_or_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/device.py\u001b[0m in \u001b[0;36mmerge_device\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \"\"\"\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_device_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mcurrent_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/device.py\u001b[0m in \u001b[0;36mfrom_string\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/device.py\u001b[0m in \u001b[0;36mparse_from_string\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mly\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=g-explicit-bool-comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown attribute: '%s' in '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown attribute: 'сpu' in '/сpu:0'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.GIT_VERSION, tf.VERSION)\n",
    "\n",
    "for device in [ 'сpu']:\n",
    "    print(device)\n",
    "    with tf.device('/{}:0'.format(device)):\n",
    "        var = tf.get_variable('var{}'.format(device), shape=[1], dtype='int32')\n",
    "        vari = tf.assign(var, [23])\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(vari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-f97b5838a8be>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-f97b5838a8be>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    gpu(:%d)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "/gpu:%d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained_lstm.ckpt-90000\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key rnn/basic_lstm_cell/bias not found in checkpoint\n\t [[Node: save_4/RestoreV2_9 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_4/Const_0_0, save_4/RestoreV2_9/tensor_names, save_4/RestoreV2_9/shape_and_slices)]]\n\t [[Node: save_4/RestoreV2_3/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_38_save_4/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save_4/RestoreV2_9', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-b73f68ac43c9>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key rnn/basic_lstm_cell/bias not found in checkpoint\n\t [[Node: save_4/RestoreV2_9 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_4/Const_0_0, save_4/RestoreV2_9/tensor_names, save_4/RestoreV2_9/shape_and_slices)]]\n\t [[Node: save_4/RestoreV2_3/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_38_save_4/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key rnn/basic_lstm_cell/bias not found in checkpoint\n\t [[Node: save_4/RestoreV2_9 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_4/Const_0_0, save_4/RestoreV2_9/tensor_names, save_4/RestoreV2_9/shape_and_slices)]]\n\t [[Node: save_4/RestoreV2_3/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_38_save_4/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b73f68ac43c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key rnn/basic_lstm_cell/bias not found in checkpoint\n\t [[Node: save_4/RestoreV2_9 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_4/Const_0_0, save_4/RestoreV2_9/tensor_names, save_4/RestoreV2_9/shape_and_slices)]]\n\t [[Node: save_4/RestoreV2_3/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_38_save_4/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save_4/RestoreV2_9', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-b73f68ac43c9>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key rnn/basic_lstm_cell/bias not found in checkpoint\n\t [[Node: save_4/RestoreV2_9 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_4/Const_0_0, save_4/RestoreV2_9/tensor_names, save_4/RestoreV2_9/shape_and_slices)]]\n\t [[Node: save_4/RestoreV2_3/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_38_save_4/RestoreV2_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we’ll load some movie reviews from our test set. Remember, these are reviews that the model has not been trained on and has never seen before. The accuracy for each test batch can be seen when you run the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value rnn/basic_lstm_cell/kernel\n\t [[Node: rnn/basic_lstm_cell/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/basic_lstm_cell/kernel)]]\n\t [[Node: Mean/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_213_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rnn/basic_lstm_cell/kernel/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-db6a6fc2c55e>\", line 3, in <module>\n    value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 891, in __call__\n    output, new_state = self._cell(inputs, state, scope)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 438, in call\n    self._linear = _Linear([inputs, h], 4 * self._num_units, True)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1171, in __init__\n    initializer=kernel_initializer)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\n    return custom_getter(**custom_getter_kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 186, in _rnn_get_variable\n    variable = getter(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 353, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2071, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value rnn/basic_lstm_cell/kernel\n\t [[Node: rnn/basic_lstm_cell/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/basic_lstm_cell/kernel)]]\n\t [[Node: Mean/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_213_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value rnn/basic_lstm_cell/kernel\n\t [[Node: rnn/basic_lstm_cell/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/basic_lstm_cell/kernel)]]\n\t [[Node: Mean/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_213_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c11bf9708fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextBatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTestBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for this batch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value rnn/basic_lstm_cell/kernel\n\t [[Node: rnn/basic_lstm_cell/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/basic_lstm_cell/kernel)]]\n\t [[Node: Mean/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_213_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rnn/basic_lstm_cell/kernel/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-db6a6fc2c55e>\", line 3, in <module>\n    value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 891, in __call__\n    output, new_state = self._cell(inputs, state, scope)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 438, in call\n    self._linear = _Linear([inputs, h], 4 * self._num_units, True)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1171, in __init__\n    initializer=kernel_initializer)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\n    return custom_getter(**custom_getter_kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 186, in _rnn_get_variable\n    variable = getter(*args, **kwargs)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 353, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 125, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2071, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/citizen4/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value rnn/basic_lstm_cell/kernel\n\t [[Node: rnn/basic_lstm_cell/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/basic_lstm_cell/kernel)]]\n\t [[Node: Mean/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_213_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we went over a deep learning approach to sentiment analysis. We looked at the different components involved in the whole pipeline and then looked at the process of writing Tensorflow code to implement the model in practice. Finally, we trained and tested the model so that it is able to classify movie reviews.\n",
    "\n",
    "With the help of Tensorflow, you can create your own sentiment classifiers to understand the large amounts of natural language in the world, and use the results to form actionable insights. Thanks for reading and following along!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import artm\n",
    "import glob\n",
    "import os\n",
    "import artm\n",
    "import glob #module gives an opp to search for a file with a particular regex\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_vectorizer(target_batches_folder, data_path):\n",
    "    if not len(glob.glob(os.path.join(target_batches_folder, '*'))):\n",
    "        return artm.BatchVectorizer(data_path=data_path, \n",
    "                                                data_format='bow_uci',\n",
    "                                                collection_name=data_path, \n",
    "                                                target_folder=target_batches_folder)\n",
    "    else:\n",
    "        return artm.BatchVectorizer(data_path=target_batches_folder, data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict(target_batches_folder):\n",
    "    dict_name = os.path.join(target_batches_folder, \"dict.txt\")\n",
    "    dictionary = artm.Dictionary(name=\"dictionary\")\n",
    "    if not os.path.exists(dict_name):\n",
    "        dictionary.gather(target_batches_folder)\n",
    "        dictionary.save_text(dict_name)\n",
    "    else:\n",
    "        dictionary.load_text(dict_name)\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, tracker_name=\"top_tokens\"):\n",
    "    for topic_name in model.topic_names:\n",
    "        print(topic_name + ': ')\n",
    "        if topic_named in last_tokens:\n",
    "            for word in model.score_tracker[tracker_name].last_tokens[topic_name]:\n",
    "                print (word)\n",
    "        else:\n",
    "            print(\"free topic\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_topic_names(topic_count, background_topic_count):\n",
    "\n",
    "    background_topics, objective_topics, all_topics = [], [], []\n",
    "    for i in range(topic_count):\n",
    "        topic_name = (\"background_topic_\" + str(i)) if i < background_topic_count \\\n",
    "            else (\"objective_topic_\" + str(i - background_topic_count))\n",
    "        all_topics.append(topic_name)\n",
    "        if i < background_topic_count:\n",
    "            background_topics.append(topic_name)\n",
    "        else:\n",
    "            objective_topics.append(topic_name)\n",
    "    return all_topics, objective_topics, background_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_regularizers(model, devided, topic_names,  **regs):\n",
    "    all_topics, objective_topics, background_topics = topic_names\n",
    "    if devided:\n",
    "            if 'objective_sparse_phi' in regs:\n",
    "                    model.regularizers.add(\n",
    "                        artm.SmoothSparsePhiRegularizer(\n",
    "                            name='objective_sparse_phi',\n",
    "                            topic_names=objective_topics,\n",
    "                            tau=regs['objective_sparse_phi']),\n",
    "                        overwrite= True)\n",
    "            if 'objective_sparse_theta' in regs:\n",
    "                    model.regularizers.add(\n",
    "                        artm.SmoothSparseThetaRegularizer(\n",
    "                            name='objective_sparse_theta',\n",
    "                            topic_names=objective_topics,\n",
    "                            tau=regs['objective_sparse_theta']),\n",
    "                        overwrite= True)\n",
    "            if 'background_sparse_phi' in regs:\n",
    "                    model.regularizers.add(\n",
    "                        artm.SmoothSparsePhiRegularizer(\n",
    "                            name='background_sparse_phi',\n",
    "                            topic_names=background_topics,\n",
    "                            tau=regs['background_sparse_phi']),\n",
    "                        overwrite= True)\n",
    "            if 'background_sparse_theta' in regs:\n",
    "                    model.regularizers.add(\n",
    "                        artm.SmoothSparseThetaRegularizer(\n",
    "                            name='background_sparse_theta',\n",
    "                            topic_names=background_topics,\n",
    "                            tau=regs['background_sparse_theta']),\n",
    "                        overwrite=True)\n",
    "    else:\n",
    "        if 'sparse_phi' in regs:\n",
    "                    model.regularizers.add(\n",
    "                        artm.SmoothSparsePhiRegularizer(\n",
    "                            name='sparse_phi',\n",
    "                            tau=regs['sparse_phi']),\n",
    "                        overwrite=True)\n",
    "        if 'sparse_theta' in regs:\n",
    "                    model.regularizers.add(\n",
    "                        artm.SmoothSparseThetaRegularizer(\n",
    "                            name='sparse_theta',\n",
    "                            tau=regs['sparse_theta']),\n",
    "                        overwrite=True)\n",
    "    if  'decorrelator_phi' in regs:\n",
    "            if devided:\n",
    "                model.regularizers.add(\n",
    "                            artm.DecorrelatorPhiRegularizer(\n",
    "                                name='decorrelator_phi',\n",
    "                                topic_names=objective_topics,\n",
    "                                tau=regs['decorrelator_phi']),\n",
    "                            overwrite=True)\n",
    "            else:\n",
    "                model.regularizers.add(\n",
    "                            artm.DecorrelatorPhiRegularizer(\n",
    "                                name='decorrelator_phi',\n",
    "                                tau=regs['decorrelator_phi']),\n",
    "                            overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_scores(model, topic_names, devided=True,  **scores):\n",
    "    #if not ('perplexity_score' in [score.name for\n",
    "    #                               score in model.scores]):\n",
    "    #    model.scores.add(PerplexityScore(name='perplexity_score'))\n",
    "    all_topics, objective_topics ,background_topics = topic_names\n",
    "    if 'top_tokens' in scores:\n",
    "        model.scores.add(artm.TopTokensScore(\n",
    "            name='top_tokens',\n",
    "            num_tokens=scores['top_tokens']),\n",
    "            overwrite= True)\n",
    "    if 'top_tokens_extended' in scores:\n",
    "        model.scores.add(artm.TopTokensScore(\n",
    "            name='top_tokens_extended',\n",
    "            num_tokens=scores['top_tokens_extended']),\n",
    "            overwrite= True)\n",
    "\n",
    "    if devided:\n",
    "            if 'objective_sparsity_phi' in scores:\n",
    "                    model.scores.add(\n",
    "                        artm.SparsityPhiScore(\n",
    "                            name='objective_sparsity_phi',\n",
    "                            topic_names=objective_topics),\n",
    "                        overwrite= True)\n",
    "            if 'objective_sparsity_theta' in scores:\n",
    "                    model.scores.add(\n",
    "                        artm.SparsityThetaScore(\n",
    "                            name='objective_sparsity_theta',\n",
    "                            topic_names=objective_topics),\n",
    "                        overwrite= True)\n",
    "            if 'background_sparsity_phi' in scores:\n",
    "                    model.scores.add(\n",
    "                        artm.SparsityPhiScore(\n",
    "                            name='background_sparsity_phi',\n",
    "                            topic_names=background_topics),\n",
    "                        overwrite= True)\n",
    "            if 'background_sparsityity_theta' in scores:\n",
    "                    model.scores.add(\n",
    "                        artm.SparsityThetaScore(\n",
    "                            name='background_sparsity_theta',\n",
    "                            topic_names=background_topics),\n",
    "                        overwrite=True)\n",
    "    else:\n",
    "        if 'sparsity_phi' in scores:\n",
    "                    print ('if sparsity_phi in scores:')\n",
    "                    model.scores.add(\n",
    "                        artm.SparsityPhiScore(\n",
    "                            name='sparsity_phi'),\n",
    "                        overwrite=True)\n",
    "        if 'sparsity_theta' in scores:\n",
    "                    print ('sparsity_theta  in scores')\n",
    "                    model.scores.add(\n",
    "                        artm.SparsityThetaScore(\n",
    "                            name='sparsity_theta'),\n",
    "                        overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_scores(topic_names):\n",
    "    # background_topics = (background_topics if background_topics else topics_amount//10)\n",
    "\n",
    "    all_topics, objective_topics, background_topics = topic_names\n",
    "    print(\"get_scores\", all_topics)\n",
    "    print(\"get scores : \" , background_topics)\n",
    "    print (\"get_scores : \" , objective_topics)\n",
    "\n",
    "    scores_list=[]\n",
    "    scores_list.append(artm.PerplexityScore(name='objective_perplexity_score',\n",
    "                                            topic_names=objective_topics))\n",
    "    scores_list.append(artm.SparsityPhiScore(name='objective_sparsity_phi',\n",
    "                                             topic_names=objective_topics))\n",
    "    scores_list.append(artm.SparsityThetaScore(name='objective_sparsity_theta',\n",
    "                                               topic_names=objective_topics))\n",
    "\n",
    "    scores_list.append(artm.PerplexityScore(name='perplexity_score',\n",
    "                                            topic_names=all_topics))\n",
    "\n",
    "    scores_list.append(artm.SparsityThetaScore(name='background_sparsity_theta',\n",
    "                                               topic_names=background_topics))\n",
    "    scores_list.append(artm.SparsityPhiScore(name='background_sparsity_phi',\n",
    "                                               topic_names=background_topics))\n",
    "    scores_list.append(artm.TopTokensScore(name=\"top_words\",\n",
    "                                              num_tokens=10, topic_names=objective_topics))\n",
    "    return scores_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Batch vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_vectorizer = get_batch_vectorizer(\"nytimes_batches\", \"nytimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary=get_dict(\"nytimes_batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_vectorizer.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 150\n",
    "topic_names = generate_topic_names(T, 10)\n",
    "all_topics, objective_topics, background_topics = topic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model = artm.ARTM(num_topics=T,\n",
    "                          topic_names = topic_names[0],\n",
    "                          cache_theta=True,\n",
    "                          reuse_theta=True,\n",
    "                          theta_columns_naming=\"title\",\n",
    "                          seed=4242,\n",
    "                          num_document_passes=3,\n",
    "                          num_processors = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_num_tokens =20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                                                 add some scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.scores.add(artm.PerplexityScore(name='perplexity_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top tokens score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.scores.add(\n",
    "    artm.TopTokensScore(\n",
    "        name='top_tokens',\n",
    "        num_tokens=_num_tokens, \n",
    "        topic_names=all_topics,\n",
    "        ),overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective_sparsity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.scores.add(\n",
    "    artm.SparsityPhiScore(\n",
    "        name='objective_sparsity_phi', \n",
    "        topic_names=objective_topics), overwrite=True)\n",
    "devided_model.scores.add(\n",
    "    artm.SparsityThetaScore(\n",
    "        name='objective_sparsity_theta',\n",
    "        topic_names=objective_topics),overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background_sparsity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.scores.add(\n",
    "        artm.SparsityPhiScore(\n",
    "            name='background_sparsity_phi',\n",
    "            topic_names=background_topics))\n",
    "devided_model.scores.add(\n",
    "    artm.SparsityThetaScore(\n",
    "        name='background_sparsity_theta',\n",
    "        topic_names=background_topics),overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add regulirizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regs = {\n",
    "    \"objective_sparse_phi\":20,\n",
    "    'objective_sparse_theta':-10,   \n",
    "    'background_sparse_phi':2, \n",
    "    'background_sparse_theta':-6,\n",
    "    'decorrelator_phi':100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add objective regulirizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.regularizers.add(\n",
    "                        artm.SmoothSparsePhiRegularizer(\n",
    "                            name='objective_sparse_phi',\n",
    "                            topic_names=objective_topics,\n",
    "                            tau=regs['objective_sparse_phi']),overwrite=True)\n",
    "devided_model.regularizers.add(\n",
    "                        artm.SmoothSparseThetaRegularizer(\n",
    "                            name='objective_sparse_theta',\n",
    "                            topic_names=objective_topics,\n",
    "                            tau=regs['objective_sparse_theta']),overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add background regulirizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.regularizers.add(\n",
    "                        artm.SmoothSparsePhiRegularizer(\n",
    "                            name='background_sparse_phi',\n",
    "                            topic_names=background_topics,\n",
    "                            tau=regs['background_sparse_phi']),\n",
    "                            overwrite= True)\n",
    "devided_model.regularizers.add(\n",
    "                        artm.SmoothSparseThetaRegularizer(\n",
    "                            name='background_sparse_theta',\n",
    "                            topic_names=background_topics,\n",
    "                            tau=regs['background_sparse_theta']),\n",
    "                            overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add decorrelator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.regularizers.add(\n",
    "            artm.DecorrelatorPhiRegularizer(\n",
    "                name='decorrelator_phi',\n",
    "                topic_names=objective_topics,\n",
    "                tau=regs['decorrelator_phi']),overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reinitialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.initialize(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.fit_online(batch_vectorizer=batch_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devided_model.score_tracker['top_tokens'].last_tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in devided_model.topic_names:\n",
    "    if topic_name in devided_model.score_tracker['top_tokens'].last_tokens:\n",
    "        print(topic_name + ': 'И+ ' '.join(devided_model.score_tracker['top_tokens'].last_tokens[topic_name]))\n",
    "\n",
    "print (\"Perplexity:\", devided_model.score_tracker[\"perplexity_score\"].last_value)\n",
    "print (devided_model.get_phi())\n",
    "print(devided_model.get_theta())\n",
    "#for i,raw in enumerate(devided_model.get_phi()):\n",
    "#    print(i,' ',raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(devided_model.score_tracker[\"perplexity_score\"].value[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'col1': ts1, 'col2': ts2}\n",
    "df = DataFrame(data=d, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    file_name = 'model_' + str(T) + str(model.score_tracker[\"perplexity_score\"])\n",
    "    model.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
